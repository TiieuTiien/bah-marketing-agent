{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e2378ee",
   "metadata": {},
   "source": [
    "# Pipeline Tạo Bộ Dữ Liệu Prompt cho Agent Đánh giá Sách\n",
    "\n",
    "Notebook này thực hiện một quy trình hoàn chỉnh để tự động tạo ra các prompt (câu lệnh) dùng để đánh giá sách. Quy trình bao gồm các bước sau:\n",
    "\n",
    "1.  **Thiết lập & Cấu hình:** Khai báo các thư viện và biến cần thiết.\n",
    "2.  **Tải và Lấy mẫu Dữ liệu:** Đọc danh sách sách từ file CSV và chọn ra một số lượng sách ngẫu nhiên để xử lý.\n",
    "3.  **Tạo Yêu cầu hàng loạt (Batch Requests):** Với mỗi cuốn sách, tạo một yêu cầu để Gemini tự sinh ra một chủ đề đánh giá sách thú vị.\n",
    "4.  **Thực thi & Chờ Tác vụ:** Gửi tất cả các yêu cầu lên Gemini API dưới dạng một tác vụ hàng loạt (batch job) và chờ cho đến khi hoàn tất.\n",
    "5.  **Xử lý & Lưu Kết quả:** Tổng hợp dữ liệu sách ban đầu với các prompt được tạo ra và lưu kết quả cuối cùng vào một file JSON.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c75f2b",
   "metadata": {},
   "source": [
    "### 1. Thiết lập & Cấu hình\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24920313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data\n",
      "Lỗi: Không thể kết nối tới Gemini API. Vui lòng kiểm tra API key. Chi tiết: Missing key inputs argument! To use the Google AI API, provide (`api_key`) arguments. To use the Google Cloud API, provide (`vertexai`, `project` & `location`) arguments.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- CÁC THAM SỐ CẤU HÌNH ---\n",
    "INPUT_CSV_FILE = \"data/sampled_books_eng_400.csv\"  # File chứa tên sách và mô tả\n",
    "OUTPUT_JSON_FILE = \"data/book_review_agent_prompts.json\"  # File kết quả cuối cùng\n",
    "BOOKS_TO_PROCESS = 100  # Số lượng sách muốn xử lý trong một lần chạy\n",
    "\n",
    "os.makedirs(\n",
    "    os.path.dirname(OUTPUT_JSON_FILE), exist_ok=True\n",
    ")  # Tạo thư mục nếu chưa tồn tại\n",
    "\n",
    "try:\n",
    "    client = genai.Client()\n",
    "    print(\"Kết nối tới Gemini API thành công.\")\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"Lỗi: Không thể kết nối tới Gemini API. Vui lòng kiểm tra API key. Chi tiết: {e}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236c0a71",
   "metadata": {},
   "source": [
    "### 2. Tải và Lấy mẫu Dữ liệu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff78098",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_books_data = []\n",
    "try:\n",
    "    with open(INPUT_CSV_FILE, \"r\", encoding=\"utf-8\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            all_books_data.append(\n",
    "                {\n",
    "                    \"title\": row.get(\"title\", \"Unknown Title\"),\n",
    "                    \"description\": row.get(\"description\", \"No Description Available\"),\n",
    "                }\n",
    "            )\n",
    "    print(f\"Đã đọc thành công {len(all_books_data)} cuốn sách từ '{INPUT_CSV_FILE}'.\")\n",
    "except FileNotFoundError:\n",
    "    print(\n",
    "        f\"Lỗi: Không tìm thấy file '{INPUT_CSV_FILE}'. Vui lòng kiểm tra lại đường dẫn.\"\n",
    "    )\n",
    "    all_books_data = []  # Gán lại là list rỗng để các cell sau không bị lỗi\n",
    "\n",
    "# Lấy mẫu ngẫu nhiên từ danh sách đã đọc\n",
    "if all_books_data:\n",
    "    if len(all_books_data) > BOOKS_TO_PROCESS:\n",
    "        sampled_books = random.sample(all_books_data, BOOKS_TO_PROCESS)\n",
    "        print(f\"Đã lấy ngẫu nhiên {len(sampled_books)} cuốn sách để xử lý.\")\n",
    "    else:\n",
    "        sampled_books = all_books_data\n",
    "        print(\n",
    "            f\"Số lượng sách ít hơn hoặc bằng {BOOKS_TO_PROCESS}. Xử lý toàn bộ {len(sampled_books)} cuốn sách.\"\n",
    "        )\n",
    "else:\n",
    "    sampled_books = []\n",
    "\n",
    "sampled_books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e64455",
   "metadata": {},
   "source": [
    "### 3. Tạo Yêu cầu hàng loạt (Batch Requests)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d140229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focus_clear_prompt(title, description):\n",
    "    return f\"\"\"\n",
    "    Bạn là một \"prompt generator\" cho đánh giá sách.\n",
    "    Viết **một prompt ngắn gọn** để đánh giá cuốn sách \"{title}\" tập trung vào một **chủ đề nổi bật, thú vị** của câu chuyện. \n",
    "    Mô tả ngắn gọn của sách: {description}\n",
    "    \n",
    "    Yêu cầu:\n",
    "    - Chỉ trả về duy nhất một prompt, không giải thích hay liệt kê nhiều ví dụ.\n",
    "    - Prompt phải rõ ràng, súc tích và gợi mở một góc nhìn phân tích sâu sắc.\n",
    "\n",
    "    Ví dụ đầu ra mong muốn:\n",
    "    Tôi muốn viết bài đánh giá về cuốn sách \"Hoàng Tử Bé\" tập trung vào sự đối lập giữa sự ngây thơ của trẻ con với sự khô khan, thực dụng của người lớn.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6b28a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tạo thành công 100 yêu cầu cho batch job.\n"
     ]
    }
   ],
   "source": [
    "batch_requests = []\n",
    "if sampled_books:\n",
    "    for book in sampled_books:\n",
    "        title = book[\"title\"]\n",
    "        description = book[\"description\"]\n",
    "\n",
    "        prompt_template = focus_clear_prompt(title, description)\n",
    "\n",
    "        request_obj = {\n",
    "            \"contents\": [{\"parts\": [{\"text\": prompt_template}], \"role\": \"user\"}]\n",
    "        }\n",
    "        batch_requests.append(request_obj)\n",
    "\n",
    "    print(f\"Đã tạo thành công {len(batch_requests)} yêu cầu cho batch job.\")\n",
    "else:\n",
    "    print(\"Không có sách nào để tạo yêu cầu.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a57582",
   "metadata": {},
   "source": [
    "### 4. Thực thi & Chờ Tác vụ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987e289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = None\n",
    "if batch_requests:\n",
    "    print(\"Đang gửi batch job lên Gemini API...\")\n",
    "    batch_job = client.batches.create(model=\"gemini-2.0-flash\", src=batch_requests)\n",
    "    print(f\"Đã tạo batch job thành công: {batch_job.name}\")\n",
    "\n",
    "    # Chờ cho tác vụ hoàn thành\n",
    "    while batch_job.state.name not in (\n",
    "        \"JOB_STATE_SUCCEEDED\",\n",
    "        \"JOB_STATE_FAILED\",\n",
    "        \"JOB_STATE_CANCELLED\",\n",
    "        \"JOB_STATE_EXPIRED\",\n",
    "    ):\n",
    "        print(f\"Trạng thái job: {batch_job.state.name}. Đang chờ 60 giây...\")\n",
    "        time.sleep(60)\n",
    "        batch_job = client.batches.get(name=batch_job.name)\n",
    "\n",
    "    print(f\"Tác vụ đã hoàn thành với trạng thái: {batch_job.state.name}\")\n",
    "else:\n",
    "    print(\"Không có yêu cầu nào để gửi đi.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7accfb37",
   "metadata": {},
   "source": [
    "### 5. Xử lý & Lưu Kết quả\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7685c89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = []\n",
    "\n",
    "if batch_job and batch_job.state.name == \"JOB_STATE_SUCCEEDED\":\n",
    "    print(\"Đang xử lý và tổng hợp kết quả...\")\n",
    "\n",
    "    for i in tqdm(range(len(sampled_books)), desc=\"Đang tổng hợp\"):\n",
    "        original_book = sampled_books[i]\n",
    "        response_item = batch_job.dest.inlined_responses[i]\n",
    "\n",
    "        generated_prompt = \"Lỗi: Không có phản hồi\"\n",
    "        if response_item.response and response_item.response.text:\n",
    "            generated_prompt = response_item.response.text.strip()\n",
    "\n",
    "        final_dataset.append(\n",
    "            {\n",
    "                \"no\": i + 1,\n",
    "                \"book_title\": original_book[\"title\"],\n",
    "                \"description\": original_book[\"description\"],\n",
    "                \"generated_prompt\": generated_prompt,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Lưu kết quả ra file JSON\n",
    "    with open(OUTPUT_JSON_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(final_dataset, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(\n",
    "        f\"Hoàn tất! Đã lưu {len(final_dataset)} bản ghi vào file '{OUTPUT_JSON_FILE}'.\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"Tác vụ không thành công hoặc không có dữ liệu để xử lý. Sẽ không ghi file nào.\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
