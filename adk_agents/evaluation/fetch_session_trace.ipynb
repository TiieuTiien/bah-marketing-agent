{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffd68b5a",
   "metadata": {},
   "source": [
    "### Trích xuất kết quả\n",
    "Trích xuất các meta data của kết quả của lần đánh giá vào một file json bao gồm:\n",
    "| **Trường**                   | **Ý nghĩa**                                                                 |\n",
    "|---------------------------|------------------------------------------------------------------------|\n",
    "| eval_id                | Id của trường hợp đang được đánh giá (định danh duy nhất cho mỗi record). |\n",
    "| session_id             | Id của phiên hội thoại (chat session) tương ứng.                        |\n",
    "| tool_trajectory_avg_score | Điểm trung bình của quỹ đạo gọi tool (độ chính xác và hợp lý khi sử dụng công cụ). |\n",
    "| response_match_score   | Điểm chất lượng phản hồi, đo bằng độ tương đồng ROUGE với phản hồi chuẩn. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ea8808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "folder_path = \"../book_review_agent/.adk/parsed\"\n",
    "eval_set = \"focus_unclear\"\n",
    "\n",
    "eval_info = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "            data = json.load(json_file)\n",
    "            eval_id = eval_set + data[\"eval_case_results\"][0][\"eval_id\"]\n",
    "            session_id = data[\"eval_case_results\"][0][\"session_id\"]\n",
    "\n",
    "            tool_trajectory_avg_score = 0\n",
    "            response_match_score = 0\n",
    "\n",
    "            overall = data[\"eval_case_results\"][0][\"overall_eval_metric_results\"]\n",
    "\n",
    "            for metric in overall:\n",
    "                if metric[\"metric_name\"] == \"tool_trajectory_avg_score\":\n",
    "                    tool_trajectory_avg_score = metric[\"score\"]\n",
    "                elif metric[\"metric_name\"] == \"response_match_score\":\n",
    "                    response_match_score = metric[\"score\"]\n",
    "\n",
    "            eval_info.append(\n",
    "                {\n",
    "                    \"eval_id\": eval_id,\n",
    "                    \"session_id\": session_id,\n",
    "                    \"tool_trajectory_avg_score\": tool_trajectory_avg_score,\n",
    "                    \"response_match_score\": response_match_score,\n",
    "                }\n",
    "            )\n",
    "\n",
    "output_filepath = f\"data/{eval_set}_eval.json\"\n",
    "\n",
    "with open(output_filepath, \"w\", encoding=\"utf-8\") as output_file:\n",
    "    json.dump(eval_info, output_file, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Dữ liệu đã được lưu vào {output_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961c496c",
   "metadata": {},
   "source": [
    "### Lưu kết quả cụ thể\n",
    "Lưu kết quả cụ thể của các phiên chạy vào folder `../session_traces` dựa vào file kết quả vừa trích xuất."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1689f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Đường dẫn đến tệp JSON chứa danh sách session_id\n",
    "input_filepath = f'data/{eval_set}_eval.json'\n",
    "\n",
    "# Thư mục để lưu các tệp session trace\n",
    "output_folder = f'session_traces_{eval_set}'\n",
    "os.makedirs(output_folder, exist_ok=True)  # Tạo thư mục nếu chưa tồn tại\n",
    "\n",
    "# URL endpoint\n",
    "base_url = 'http://127.0.0.1:8000/debug/trace/session'\n",
    "\n",
    "# Đọc danh sách session_id từ tệp JSON\n",
    "with open(input_filepath, 'r', encoding='utf-8') as file:\n",
    "    eval_info = json.load(file)\n",
    "\n",
    "for item in eval_info:\n",
    "    session_id = item[\"session_id\"]\n",
    "    url = f\"{base_url}/{session_id}\"\n",
    "    print(f\"Fetching session trace for session_id: {session_id}\")\n",
    "\n",
    "    try:\n",
    "        # Gửi yêu cầu GET\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Kiểm tra nếu có lỗi HTTP\n",
    "\n",
    "        # Lưu kết quả vào tệp JSON\n",
    "        output_filepath = os.path.join(output_folder, f\"{session_id}.json\")\n",
    "        with open(output_filepath, 'w', encoding='utf-8') as output_file:\n",
    "            json.dump(response.json(), output_file, indent=4, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"Saved session trace to: {output_filepath}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to fetch session trace for session_id {session_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7883a0",
   "metadata": {},
   "source": [
    "### Trích xuất dữ liệu chi tiết từ các file đã lưu\n",
    "\n",
    "File kết quả gồm 100 bản ghi, các trường dữ liệu được mô tả như sau:\n",
    "\n",
    "| **Trường**                   | **Ý nghĩa**                                                                 |\n",
    "|---------------------------|------------------------------------------------------------------------|\n",
    "| eval_id                | Id của trường hợp đang được đánh giá (định danh duy nhất cho mỗi record). |\n",
    "| session_id             | Id của phiên hội thoại (chat session) tương ứng.                        |\n",
    "| tool_trajectory_avg_score | Điểm trung bình của quỹ đạo gọi tool (độ chính xác và hợp lý khi sử dụng công cụ). |\n",
    "| response_match_score   | Điểm chất lượng phản hồi, đo bằng độ tương đồng ROUGE với phản hồi chuẩn. |\n",
    "| invocation_duration_ms | Thời gian thực thi toàn bộ (bao gồm model, tool và overhead), tính bằng millisecond. |\n",
    "| llm_duration_ms        | Thời gian mà LLM tiêu tốn để sinh phản hồi.                             |\n",
    "| tool_duration_ms       | Tổng thời gian các công cụ được gọi chạy thực tế.                        |\n",
    "| overhead_duration_ms   | Thời gian overhead phát sinh ngoài LLM và tool (ví dụ chuẩn bị dữ liệu, xử lý trung gian). |\n",
    "| total_input_tokens     | Tổng số tokens đầu vào mà LLM nhận trong toàn bộ phiên.                  |\n",
    "| total_output_tokens    | Tổng số tokens đầu ra mà LLM sinh ra trong toàn bộ phiên.                |\n",
    "| total_tokens           | Tổng số tokens đã dùng (đầu vào + đầu ra).                              |\n",
    "| num_llm_calls          | Số lần LLM được gọi trong một bản ghi.                                  |\n",
    "| num_tool_calls         | Số lần công cụ được gọi.                                                |\n",
    "| total_spans            | Tổng số đoạn (spans) được theo dõi/trích xuất trong toàn bộ quá trình.   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cf6d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Cấu hình Toàn cục ---\n",
    "# Tệp JSON chứa danh sách các case cần đánh giá\n",
    "INPUT_EVAL_FILE = f\"data/{eval_set}_eval.json\"\n",
    "# Thư mục để lưu trữ (cache) các file trace đã tải về\n",
    "SESSION_TRACES_FOLDER = f\"session_traces/{eval_set}\"\n",
    "# Tệp JSON đầu ra cuối cùng chứa kết quả phân tích\n",
    "FINAL_OUTPUT_FILE = f\"data/{eval_set}_eval_detail.json\"\n",
    "\n",
    "# URL endpoint để lấy trace\n",
    "BASE_URL = \"http://127.0.0.1:8000/debug/trace/session\"\n",
    "\n",
    "# Danh sách các agent cha mục tiêu để lọc các lần gọi LLM\n",
    "TARGET_PARENT_AGENTS = {\n",
    "    \"agent_run [creative_assistant_agent]\",\n",
    "    \"agent_run [writer_agent]\",\n",
    "    \"agent_run [critic_agent]\",\n",
    "    \"agent_run [save_draft_agent]\",\n",
    "    \"agent_run [confirmation_agent]\",\n",
    "    \"agent_run [research_agent]\",\n",
    "}\n",
    "\n",
    "# --- 2. Logic Chính ---\n",
    "\n",
    "# Tạo thư mục lưu trữ nếu chưa có\n",
    "os.makedirs(SESSION_TRACES_FOLDER, exist_ok=True)\n",
    "\n",
    "# Đọc tệp JSON đầu vào\n",
    "if not os.path.exists(INPUT_EVAL_FILE):\n",
    "    print(f\"Lỗi: Không tìm thấy tệp đầu vào tại '{INPUT_EVAL_FILE}'\")\n",
    "else:\n",
    "    with open(INPUT_EVAL_FILE, \"r\", encoding=\"utf-8\") as file:\n",
    "        eval_info = json.load(file)\n",
    "\n",
    "    # Lặp qua từng case đánh giá với thanh tiến trình\n",
    "    for item in tqdm(eval_info, desc=\"Processing and Analyzing Sessions\"):\n",
    "        session_id = item.get(\"session_id\")\n",
    "        if not session_id:\n",
    "            continue\n",
    "\n",
    "        trace_data = None\n",
    "        trace_filepath = os.path.join(SESSION_TRACES_FOLDER, f\"{session_id}.json\")\n",
    "\n",
    "        try:\n",
    "            # --- Bước A: Lấy dữ liệu Trace (từ file cache hoặc API) ---\n",
    "            if os.path.exists(trace_filepath):\n",
    "                # Nếu đã có file, đọc từ cache\n",
    "                with open(trace_filepath, \"r\", encoding=\"utf-8\") as trace_file:\n",
    "                    trace_data = json.load(trace_file)\n",
    "            else:\n",
    "                # Nếu chưa có, gọi API để tải về\n",
    "                response = requests.get(url=f\"{BASE_URL}/{session_id}\")\n",
    "                response.raise_for_status()\n",
    "                trace_data = response.json()\n",
    "                # Và lưu lại vào cache cho lần sau\n",
    "                with open(trace_filepath, \"w\", encoding=\"utf-8\") as output_file:\n",
    "                    json.dump(trace_data, output_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "            # --- Bước B: Phân tích dữ liệu Trace đã có ---\n",
    "            if trace_data and isinstance(trace_data, list):\n",
    "                # Khởi tạo các biến\n",
    "                total_input_tokens, total_output_tokens = 0, 0\n",
    "                llm_duration_ns, tool_duration_ns = 0, 0\n",
    "                num_llm_calls, num_tool_calls = 0, 0\n",
    "\n",
    "                span_id_to_name_map = {\n",
    "                    span[\"span_id\"]: span.get(\"name\") for span in trace_data\n",
    "                }\n",
    "\n",
    "                for trace in trace_data:\n",
    "                    duration_ns = trace.get(\"end_time\", 0) - trace.get(\"start_time\", 0)\n",
    "\n",
    "                    if trace.get(\"name\") == \"call_llm\":\n",
    "                        parent_id = trace.get(\"parent_span_id\")\n",
    "                        if (\n",
    "                            parent_id\n",
    "                            and span_id_to_name_map.get(parent_id)\n",
    "                            in TARGET_PARENT_AGENTS\n",
    "                        ):\n",
    "                            num_llm_calls += 1\n",
    "                            llm_duration_ns += duration_ns\n",
    "                            attrs = trace.get(\"attributes\", {})\n",
    "                            total_input_tokens += attrs.get(\n",
    "                                \"gen_ai.usage.input_tokens\", 0\n",
    "                            )\n",
    "                            total_output_tokens += attrs.get(\n",
    "                                \"gen_ai.usage.output_tokens\", 0\n",
    "                            )\n",
    "\n",
    "                    elif str(trace.get(\"name\")).startswith(\"execute_tool\"):\n",
    "                        num_tool_calls += 1\n",
    "                        tool_duration_ns += duration_ns\n",
    "\n",
    "                root_span = next(\n",
    "                    (s for s in trace_data if not s.get(\"parent_span_id\")),\n",
    "                    trace_data[-1],\n",
    "                )\n",
    "                invocation_duration_ns = root_span.get(\"end_time\", 0) - root_span.get(\n",
    "                    \"start_time\", 0\n",
    "                )\n",
    "\n",
    "                # Thêm tất cả các trường kết quả vào item\n",
    "                item[\"invocation_duration_ms\"] = invocation_duration_ns / 1_000_000\n",
    "                item[\"llm_duration_ms\"] = llm_duration_ns / 1_000_000\n",
    "                item[\"tool_duration_ms\"] = tool_duration_ns / 1_000_000\n",
    "                item[\"overhead_duration_ms\"] = (\n",
    "                    invocation_duration_ns - llm_duration_ns - tool_duration_ns\n",
    "                ) / 1_000_000\n",
    "                item[\"total_input_tokens\"] = total_input_tokens\n",
    "                item[\"total_output_tokens\"] = total_output_tokens\n",
    "                item[\"total_tokens\"] = total_input_tokens + total_output_tokens\n",
    "                item[\"num_llm_calls\"] = num_llm_calls\n",
    "                item[\"num_tool_calls\"] = num_tool_calls\n",
    "                item[\"total_spans\"] = len(trace_data)\n",
    "\n",
    "        except (requests.exceptions.RequestException, json.JSONDecodeError) as e:\n",
    "            print(f\"\\nLỗi xử lý session {session_id}: {e}\")\n",
    "            # Gắn None cho các trường nếu có lỗi\n",
    "            keys_to_nullify = [\n",
    "                \"invocation_duration_ms\",\n",
    "                \"llm_duration_ms\",\n",
    "                \"tool_duration_ms\",\n",
    "                \"overhead_duration_ms\",\n",
    "                \"total_input_tokens\",\n",
    "                \"total_output_tokens\",\n",
    "                \"total_tokens\",\n",
    "                \"num_llm_calls\",\n",
    "                \"num_tool_calls\",\n",
    "                \"total_spans\",\n",
    "            ]\n",
    "            for key in keys_to_nullify:\n",
    "                item[key] = None\n",
    "\n",
    "    # --- 3. Lưu kết quả cuối cùng ---\n",
    "    with open(FINAL_OUTPUT_FILE, \"w\", encoding=\"utf-8\") as output_file:\n",
    "        json.dump(eval_info, output_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(\n",
    "        f\"\\nQuy trình hoàn tất! Dữ liệu đã được làm giàu và lưu vào {FINAL_OUTPUT_FILE}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe291621",
   "metadata": {},
   "source": [
    "### Lưu dữ liệu thành csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b16e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Tên tệp JSON đầu vào\n",
    "input_filename = f'data/{eval_set}_eval_detail.json' # Hãy chắc chắn rằng bạn đã lưu file JSON với tên này\n",
    "\n",
    "# Tên tệp CSV đầu ra\n",
    "output_filename = f'data/{eval_set}_eval_detail.csv'\n",
    "\n",
    "# Đọc trực tiếp từ tệp JSON vào DataFrame\n",
    "df = pd.read_json(input_filename)\n",
    "\n",
    "# Ghi DataFrame ra tệp CSV\n",
    "df.to_csv(output_filename, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Chuyển đổi thành công! Dữ liệu đã được lưu vào tệp '{output_filename}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".adk.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
